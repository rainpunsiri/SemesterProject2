# -*- coding: utf-8 -*-
"""2streamlit_app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wo0OE_jO99MH9UUQm3zeBmMWygbJmJWr
"""

#import libraries
import streamlit as st
import pandas as pd
import requests
import json

#change those IDs to readable names
series_ids = ['LNS11000000', 'LNS13000000', 'LNS14000000', 'CES0000000001']
series_names = {
    "LNS11000000": "Civilian Labor Force",
    "LNS13000000": "Civilian Unemployment",
    "LNS14000000": "Unemployment Rate",
    "CES0000000001": "Total Nonfarm Employment"
}

headers = {'Content-type': 'application/json'}
payload = json.dumps({
    "seriesid": series_ids,
    "startyear": "2014",
    "endyear": "2024"
})

#process data
@st.cache_data(ttl="1d")
def collect_and_process_data():
    response = requests.post(
        'https://api.bls.gov/publicAPI/v2/timeseries/data/',
        headers=headers,
        data=payload
    )
    json_data = json.loads(response.text)

    dataframes_dict = {}
    for series in json_data['Results']['series']:
        series_id = series['seriesID']
        parsed_data = []

        for item in series['data']:
            year = item['year']
            period = item['period']
            value = float(item['value'])
            month = period.replace('M', '')
            parsed_data.append({
                'Year': year,
                'Month': month,
                'Value': value,
            })

        df = pd.DataFrame(parsed_data)
        df['Date'] = pd.to_datetime(df['Year'] + '-' + df['Month'], format='%Y-%m', errors='coerce')
        dataframes_dict[series_id] = df[['Date', 'Year', 'Month', 'Value']]

    #merge datasets into one
    combined_df = dataframes_dict['LNS11000000'].rename(columns={'Value': 'Civilian Labor Force'})
    combined_df = combined_df.merge(
        dataframes_dict['LNS13000000'].rename(columns={'Value': 'Civilian Unemployment'}),
        on=['Date', 'Year', 'Month'], how='outer'
    ).merge(
        dataframes_dict['LNS14000000'].rename(columns={'Value': 'Unemployment Rate'}),
        on=['Date', 'Year', 'Month'], how='outer'
    ).merge(
        dataframes_dict['CES0000000001'].rename(columns={'Value': 'Total Nonfarm Employment'}),
        on=['Date', 'Year', 'Month'], how='outer'
    )

    return combined_df, dataframes_dict

#grab all the data
combined_df, dataframes_dict = collect_and_process_data()

#Streamlit
st.title("BLS Data Overview")
st.write("Displaying key labor statistics retrieved from the BLS API.")

#combined table with all four datasets
st.markdown("## Combined Data Table")
st.write("This table combines all four data series into one view.")
st.dataframe(combined_df, height=500)  # Set a scrollable height for the box

st.markdown("## Download Data as CSV")

# combined data download
st.subheader("Combined Data")
st.download_button(
    label="Download Combined Data",
    data=combined_df.to_csv(index=False),
    file_name="combined_bls_data.csv",
    mime="text/csv"
)

# download button for each series
st.subheader("Individual Data Series")
for series_id, df in dataframes_dict.items():
    st.download_button(
        label=f"Download {series_names[series_id]}",
        data=df.to_csv(index=False),
        file_name=f"{series_names[series_id].replace(' ', '_').lower()}.csv",
        mime="text/csv"
    )

# show raw data for each series
st.markdown("## Raw Data Tables")
for series_id, df in dataframes_dict.items():
    st.subheader(series_names[series_id])
    st.dataframe(df)